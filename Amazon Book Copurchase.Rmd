---
title: "Amazon Book Copurchase"
output:
  html_document:
    toc: yes
  pdf_document: default
---
```{r setup, include=FALSE}
library(sqldf)
library(dplyr)
library(igraph)
```
Import data

```{graph}
products <- read.csv("/Users/NINI/products.csv")
copurchase <- read.csv("/Users/NINI/copurchase.csv")
attach(products)
```

Only keep record of product whose type is Book, and clean copurchase data to make sure copurchase only has source ids and target ids from the Book product.

```{graph}
products_book = filter(products, group == "Book" & salesrank <= 150000 & salesrank >= 0)
copurchase <- sqldf("select copurchase.source, copurchase.target from copurchase, products_book 
                    where copurchase.source in (products_book.id)")

copurchase <- sqldf("select copurchase.source, copurchase.target from copurchase, products_book 
                    where copurchase.target in (products_book.id)")
```
Convert numeric of Source id and Target id into character for drawing graph later
```{graph}
copurchase$Source <- as.character(copurchase$Source)
copurchase$Target <- as.character(copurchase$Target)
attach(copurchase)
```
Convert copurchase into graph object as 'net'
```{graph}
net <- graph_from_data_frame(copurchase, directed = TRUE)
```
Output in-degree(target2product), out-degree(product2target), and all-degree
```{graph}
in_degree <- degree(net, mode = "in")
out_degree <- degree(net, mode = "out")
all_degree <- degree(net, mode = "all")
```
Select out the product id with the highest all-degree and get the product id = '33' and '4429'
```{graph}
V(net)$name[degree(net)==max(all_degree)]
```
We choose '33' to find out all books'ids connecting with '33' directly and indirectly
```{graph}
subcomponent33 <- subcomponent(net, "33", mode = "all")
```
Convert subcomponent into object as graph
```{graph}
g <- induced_subgraph(net, subcomponent33)
```
Draw out graph#
Vertex's degree is used to set vertex's size.
```{graph}
V(g)$degree <- degree(g, mode = "all")
```
Get the first shortest path between two books' ids who have longest distance.
```{graph}
diam <- get_diameter(g, directed = TRUE)
as.vector(diam)
```
Set color and size for nodes and edges for graph.
```{graph}
vcol <- rep("gray", vcount(g))
vcol[diam] <- "gold"
ecol <- rep("gray80", ecount(g))
ecol[E(g, path = diam)] <- "orange" 

plot(g, edge.arrow.size=.025, edge.color=ecol, edge.curved=0.2,
     vertex.size=V(g)$degree*0.5, 
     vertex.label = ifelse(degree(g) == 53, V(g)$name, NA), 
     vertex.label.degree = -pi/2,
     vertex.color=vcol, vertex.size=2, 
     vertex.frame.color="gray", vertex.label.color="black", 
     vertex.label.cex=0.5, vertex.label.dist=3, main = "Graph for subcomponent of Vertex '33'") 
```
According to the 'diam' nodes: 37895 27936 21584 10889 11080 14111 4429  2501  3588  6676 
From the sources and related targets, it is clear to find out that the consumers are purchasing classic, romantic and entertaining books, which are consistently related. Node "4429" reflects the popular interest for the book buyers who are also interested in the books of 1950-2000.


Degree distribution of subcomponent33, from distribution and edge density, we learned that the most books are in the low degree, meaning that most book buyers are looking for particular books and not targeting to further extent.
```{graph}
deg.dist <- degree_distribution(g, cumulative=T, mode="all")
deg <- degree(g, mode = "all")
plot( x=0:max(deg), y=1-deg.dist, pch=19, cex=1.2, col="orange", 
      xlab="Degree", ylab="Cumulative Frequency")
edge_density(g, loops=F)
```
Degree centralization: the difference between centralization 0.02794058 and theoretical max centralization 1630818 is huge. It means most of book ids with few connection with other books, but only few books has centralized the connections.
```{graph}
centr_degree(g, mode="all", normalized=T)
```
Closeness: according to closeness function result, the max closeness value is 0.0001612383, which is tiny. It means low efficiency when one node to reach other nodes.
```{graph}
closeness(g, mode="all", weights=NA) 
centr_clo(g, mode="all", normalized=T) 
```
Betweenness: most of nodes' betweenness are '0'. It means most of books are purchased solely based on the consumers' needs and not related to others.
```{graph}
betwn <- betweenness(g, directed=T, weights=NA)
boxplot(betwn)
edge_betweenness(g, directed=T, weights=NA)
centr_betw(g, directed=T, normalized=T)
```
Hubs and authorities
According to hub_score's and authority_score's distribution, we found the whole network has loose connection with each other and only very few nodes as hubs to connect to others and authorities as target, like "195144", "33".
```{graph}
hubs <- hub_score(g, weights=NA)
boxplot(hubs)
auths <- authority_score(g, weights=NA)
boxplot(auths)
hs <- hub_score(g, weights=NA)$vector
as <- authority_score(g, weights=NA)$vector

plot(g,
     vertex.size=hs*10,
     main = 'Hubs',
     vertex.color = rainbow(52),vertex.label = ifelse(degree(g) == 53, V(g)$name, NA),
     edge.arrow.size=0.025,
     layout = layout.kamada.kawai)

plot(g,
     vertex.size=as*10,
     main = 'Authorities',
     vertex.color = rainbow(52),vertex.label = ifelse(degree(g) == 53, V(g)$name, NA),
     edge.arrow.size=0.025,
     layout = layout.kamada.kawai)
```

create variables of neighbors
```{graph}
products_book_focal <- products_book
```
Create table products_book_focal_mean1 to record the means of rating, review counts, sales rank of every focal product.
```{graph}
products_book_focal_mean <- NULL
products_book_focal_mean1 <- NULL
```
Figure out all neighbors of each focal product
Define Global variable: vertexid
```{graph}
vertexid <- as_ids(V(g))
for(i in 1:904){

  neigh_nodes <- neighbors(g, vertexid[i], mode="in")
  neigh_nodes <- as_ids(neigh_nodes)
  neigh_nodes <- as.character(neigh_nodes)
  products_book_focal_temp <- filter(products_book_focal, 
                                     products_book_focal$id %in% neigh_nodes)
  products_book_focal_mean$id <- as.numeric(vertexid[i])
  products_book_focal_mean$nghb_mn_rating <- mean(products_book_focal_temp$rating)
  products_book_focal_mean$nghb_mn_salesrank <- mean(products_book_focal_temp$salesrank)
  products_book_focal_mean$nghb_mn_review_cnt <- mean(products_book_focal_temp$review_cnt)
  products_book_focal_mean1 <- rbind(products_book_focal_mean, products_book_focal_mean1)
}
products_book_focal_mean1 <- as.data.frame(products_book_focal_mean1)

```
Queation 8
All product info for subcomponent33
```{graph}
product_33 <- merge(products_book_focal, products_book_focal_mean1, by.x = "id", by.y = "id", all.y=TRUE)
```
Include Indegree, outdegree, closeness, betweenness into the products info of subcomponent 33.
```{graph}
for(i in 1:904){
  
  in_degree33 <- degree(g, vertexid[i], mode="in")
  out_degree33 <- degree(g, vertexid[i], mode="out")
  closeness33 <- closeness(g, vertexid[i], mode = "all", weights=NA)
  betweenness33 <- betweenness(g, vertexid[i], directed=T, weights=NA)
  product_33$in_degree[product_33$id == as.numeric(vertexid[i])] <- in_degree33
  product_33$out_degree[product_33$id == as.numeric(vertexid[i])] <- out_degree33
  product_33$closeness[product_33$id == as.numeric(vertexid[i])] <- closeness33
  product_33$betweenness[product_33$id == as.numeric(vertexid[i])] <- betweenness33
  
}
```
Include hub score and authority score
```{graph}
hub_auth_temp <- NULL

hub_auth_temp$id <- as.data.frame(as.numeric(vertexid))
hub_auth_temp$hub_score <- as.data.frame(hs)
hub_auth_temp$auth_score <- as.data.frame(as)
hub_auth_temp <- as.data.frame(hub_auth_temp)
colnames(hub_auth_temp) <- c("id", "hub_score", "auth_score")
```
Merge temporary table containing hub score and authority score into product33 table
```{graph}
product_33 <- merge(product_33, hub_auth_temp, by.x = "id", by.y = "id", all.x =TRUE)
product_33$nghb_mn_rating <- as.numeric(product_33$nghb_mn_rating)
product_33$nghb_mn_salesrank <- as.numeric(product_33$nghb_mn_salesrank)
product_33$nghb_mn_review_cnt <- as.numeric(product_33$nghb_mn_review_cnt)
```
Now product_33 contains all network info of books of subcomponent "33"
```{graph}
summary(product_33)
attach(product_33)
```
Following will do poission regression to check which factor impact salesrank most.
```{graph}
fit.salesrank <- glm(salesrank ~ review_cnt + downloads + rating + nghb_mn_rating + nghb_mn_salesrank + nghb_mn_review_cnt + in_degree + out_degree + closeness + betweenness + hub_score + auth_score, 
                     data = product_33, family = poisson())
summary(fit.salesrank)

```
Interprate coefficients:
```{graph}
c1 <-coef(fit.salesrank)
c1 <- as.data.frame(c1)
colnames(c1) <- c("coef_value")
attach(c1)
c1$coef_value <- round(coef_value, 4)
c1$exp_value <- round(exp(coef_value), 4)
c1$prob_percentage <- (c1$exp_value-1)*100
print(c1)
```
According to c1, we can explain the coefficients as below:
Due to we are focusing on corelationsihp of books not an isolated book, so "intercept" is not meaningful. All other characters of book are significant to sales rank.
1.Product's review counts increase by one, 2.83% decrease on salesrank on average, means more probability of sales.
2.Product's downloads impact: downloads increased by one, 2.49% increase on salesrank on average, means less probability of sales.
3.Product's rating impact: rating increased by one,  0.7% decrease on salesrank on average, means more probability of sales.
4.Neighbors' mean review amount increased by one, 0.07% increase on salesrank  on averageand less probability of sales.
5.Neighbors' mean rating increased by one, 0.97% decrease on salesrank on average, means more probability of sales.
6.Neighbors' mean salesrank increased by one, it will not impact much on focal product salesrank. But if neighbors' mean salesrank increased a lot, it will impact focal product's salesrank and sales.
7.Product's in-degree increased by one, 0.28% increase on salesrank on average, means less probability of sales.
8.Product's out-degree increased by one, 5.81% increase on salesrank on average, means less probability of sales.
9.Product's closeness increased by 0.0001, 0.01% decrease on salesrank  on averageand more sales.
10.Product's betweenness increased by one (paths are more shorter to reach others), 0.07% decrease on salesrank  on average and more sales.
11.Product's hub score increased by 0.1 (more outlinks), 2.779% increase on salesrank  on average and less sales.
12.Product's authority score increased by 0.1 (more inlinks), 2.087% increase on salesrank  on average and less sales.

Remove products with no "point-to" neighbors to do poisson regression, and get the same result as above.
```{graph}
product_33_haveneigh <- product_33[complete.cases(product_33), ]
fit.salesrank_neigh <- glm(salesrank ~ review_cnt + downloads + rating + nghb_mn_rating + nghb_mn_salesrank + nghb_mn_review_cnt + in_degree + out_degree + closeness + betweenness + hub_score + auth_score, 
                     data = product_33_haveneigh, family = poisson())
summary(fit.salesrank_neigh)
```
Predict using mean value of every variables. The predicted result of sales rank is 65799.
```{graph}
predict(fit.salesrank, data.frame(review_cnt=mean(review_cnt), downloads=mean(downloads), 
                                  rating=mean(rating), nghb_mn_rating = mean(nghb_mn_rating), 
                                  nghb_mn_salesrank =mean(nghb_mn_salesrank),
                                  nghb_mn_review_cnt = mean(nghb_mn_review_cnt), 
                                  in_degree=mean(in_degree), out_degree = mean(out_degree), 
                                  closeness = mean(closeness), betweenness = mean(betweenness),
                                  hub_score = mean(hub_score), auth_score = mean(auth_score)),
        type="response")
```
Two times neighbor average rating and keep others constant, predict the salesrank. The predicted result of sales rank is 62880.
```{graph}
predict(fit.salesrank, data.frame(review_cnt=mean(review_cnt), downloads=mean(downloads), 
                                  rating=mean(rating), nghb_mn_rating = mean(nghb_mn_rating)*2, 
                                  nghb_mn_salesrank =mean(nghb_mn_salesrank),
                                  nghb_mn_review_cnt = mean(nghb_mn_review_cnt), 
                                  in_degree=mean(in_degree), out_degree = mean(out_degree), 
                                  closeness = mean(closeness), betweenness = mean(betweenness),
                                  hub_score = mean(hub_score), auth_score = mean(auth_score)),
        type="response")
```